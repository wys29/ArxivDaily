# soft
## Dual-wavelength Fourier Ptychographic Topography
- **Url**: http://arxiv.org/abs/2512.08883v1
- **Authors**: ['Yi Shen', 'Tongyu Li', 'Hao Wang', 'Jinyong Kim', 'Hojun Lee', 'Wookrae Kim', 'Jonghyeok Park', 'Junho Shin', 'Seungbeam Park', 'Lei Tian']
- **Abstrat**: We introduce a dual-wavelength Fourier ptychographic topography (FPT) method that extends the lambda/2 height-range limit of single-wavelength FPT. By reconstructing complex fields at two illumination wavelengths and exploiting their phase difference, the method achieves an effective synthetic wavelength lambda_s and an unambiguous range of lambda_s/2 without reducing lateral resolution. A noise-robust wrapped-number search is used to select per-pixel integer pairs (k1, k2), and a global refinement with circular TV regularization and soft bounds improves stability and preserves height discontinuities. The approach is validated through rigorous scattering-model-based simulations and experiments on structured silicon samples, demonstrating accurate height recovery in regimes where single-wavelength FPT exhibits phase wrapping. We analyze the limits of the FPT forward model and identify aspect ratio (AR) and phase modulation transfer function (ph-MTF) as key predictors of reconstruction fidelity. Simulations and experiments show that increasing AR beyond a practical threshold causes loss of high-frequency phase transfer and destabilizes dual-wavelength unwrapping. Within this AR range, dual-wavelength FPT provides robust, high-resolution topography suitable for semiconductor and industrial metrology.





# robot
## Astra: General Interactive World Model with Autoregressive Denoising
- **Url**: http://arxiv.org/abs/2512.08931v1
- **Authors**: ['Yixuan Zhu', 'Jiaqi Feng', 'Wenzhao Zheng', 'Yuan Gao', 'Xin Tao', 'Pengfei Wan', 'Jie Zhou', 'Jiwen Lu']
- **Abstrat**: Recent advances in diffusion transformers have empowered video generation models to generate high-quality video clips from texts or images. However, world models with the ability to predict long-horizon futures from past observations and actions remain underexplored, especially for general-purpose scenarios and various forms of actions. To bridge this gap, we introduce Astra, an interactive general world model that generates real-world futures for diverse scenarios (e.g., autonomous driving, robot grasping) with precise action interactions (e.g., camera motion, robot action). We propose an autoregressive denoising architecture and use temporal causal attention to aggregate past observations and support streaming outputs. We use a noise-augmented history memory to avoid over-reliance on past frames to balance responsiveness with temporal coherence. For precise action control, we introduce an action-aware adapter that directly injects action signals into the denoising process. We further develop a mixture of action experts that dynamically route heterogeneous action modalities, enhancing versatility across diverse real-world tasks such as exploration, manipulation, and camera control. Astra achieves interactive, consistent, and general long-term video prediction and supports various forms of interactions. Experiments across multiple datasets demonstrate the improvements of Astra in fidelity, long-range prediction, and action alignment over existing state-of-the-art world models.





## OSMO: Open-Source Tactile Glove for Human-to-Robot Skill Transfer
- **Url**: http://arxiv.org/abs/2512.08920v1
- **Authors**: ['Jessica Yin', 'Haozhi Qi', 'Youngsun Wi', 'Sayantan Kundu', 'Mike Lambeta', 'William Yang', 'Changhao Wang', 'Tingfan Wu', 'Jitendra Malik', 'Tess Hellebrekers']
- **Abstrat**: Human video demonstrations provide abundant training data for learning robot policies, but video alone cannot capture the rich contact signals critical for mastering manipulation. We introduce OSMO, an open-source wearable tactile glove designed for human-to-robot skill transfer. The glove features 12 three-axis tactile sensors across the fingertips and palm and is designed to be compatible with state-of-the-art hand-tracking methods for in-the-wild data collection. We demonstrate that a robot policy trained exclusively on human demonstrations collected with OSMO, without any real robot data, is capable of executing a challenging contact-rich manipulation task. By equipping both the human and the robot with the same glove, OSMO minimizes the visual and tactile embodiment gap, enabling the transfer of continuous shear and normal force feedback while avoiding the need for image inpainting or other vision-based force inference. On a real-world wiping task requiring sustained contact pressure, our tactile-aware policy achieves a 72% success rate, outperforming vision-only baselines by eliminating contact-related failure modes. We release complete hardware designs, firmware, and assembly instructions to support community adoption.




