# soft
## Nonlinear Spectral Modeling and Control of Soft-Robotic Muscles from Data
- **Url**: http://arxiv.org/abs/2601.03247v1
- **Authors**: ['Leonardo Bettini', 'Amirhossein Kazemipour', 'Robert K. Katzschmann', 'George Haller']
- **Abstrat**: Artificial muscles are essential for compliant musculoskeletal robotics but complicate control due to nonlinear multiphysics dynamics. Hydraulically amplified electrostatic (HASEL) actuators, a class of soft artificial muscles, offer high performance but exhibit memory effects and hysteresis. Here we present a data-driven reduction and control strategy grounded in spectral submanifold (SSM) theory. In the adiabatic regime, where inputs vary slowly relative to intrinsic transients, trajectories rapidly converge to a low-dimensional slow manifold. We learn an explicit input-to-output map on this manifold from forced-response trajectories alone, avoiding decay experiments that can trigger hysteresis. We deploy the SSM-based model for real-time control of an antagonistic HASEL-clutch joint. This approach yields a substantial reduction in tracking error compared to feedback-only and feedforward-only baselines under identical settings. This record-and-control workflow enables rapid characterization and high-performance control of soft muscles and muscle-driven joints without detailed physics-based modeling.





## Discrete gravitational diagram technique in the soft synchronous gauge
- **Url**: http://arxiv.org/abs/2601.03228v1
- **Authors**: ['V. M. Khatsymovsky']
- **Abstrat**: This paper develops our work on the consequences of the Regge calculus, where some edge length scale arises as an optimal starting point of the perturbative expansion with taking into account a bell-shaped form of the measure obtained using functional integration over connection.   A "hypercubic" structure is considered (some variables are frozen), it is described by the metric $g_{λμ}$ at the sites.   The edge length scale as some maximum point of the measure is $\sim η^{1 / 2}$, where $η$ defines the free factor like $ ( - \det \| g_{λμ} \| )^{ η/ 2}$ in the measure and should be a large parameter to ensure true action upon integration over connection. A priori, the perturbative expansion may contain increasing powers of $η$, but this does not happen for the starting point inside some neighborhood of the maximum point of the measure, and it does happen outside this neighborhood. This appears to be a dynamic mechanism for establishing the edge length scale.   We use a discrete version of the soft synchronous gauge in the principal value type prescription we discuss in a recent paper arXiv:2601.02181. This allows one to fix the timelike length scale at a low level for which the measure is known in closed form. This gauge is considered together with a refined finite-difference form of the action to match the analytical properties of the propagator to the continuum case.





# robot
## Aligning Text, Images, and 3D Structure Token-by-Token
- **Url**: http://arxiv.org/abs/2506.08002v2
- **Authors**: ['Aadarsh Sahoo', 'Vansh Tibrewal', 'Georgia Gkioxari']
- **Abstrat**: Creating machines capable of understanding the world in 3D is essential in assisting designers that build and edit 3D environments and robots navigating and interacting within a three-dimensional space. Inspired by advances in language and image modeling, we investigate the potential of autoregressive models for a new modality: structured 3D scenes. To this end, we propose a unified LLM framework that aligns language, images, and 3D scenes and provide a detailed ''cookbook'' outlining critical design choices for achieving optimal training and performance addressing key questions related to data representation, modality-specific objectives, and more. We show how to tokenize complex 3D objects to incorporate into our structured 3D scene modality. We evaluate performance across four core 3D tasks -- rendering, recognition, instruction-following, and question-answering -- and four 3D datasets, synthetic and real-world. We show our model's effectiveness on reconstructing complete 3D scenes consisting of complex objects from a single image and on real-world 3D object recognition tasks. Project webpage: https://glab-caltech.github.io/kyvo/





## Nonlinear Spectral Modeling and Control of Soft-Robotic Muscles from Data
- **Url**: http://arxiv.org/abs/2601.03247v1
- **Authors**: ['Leonardo Bettini', 'Amirhossein Kazemipour', 'Robert K. Katzschmann', 'George Haller']
- **Abstrat**: Artificial muscles are essential for compliant musculoskeletal robotics but complicate control due to nonlinear multiphysics dynamics. Hydraulically amplified electrostatic (HASEL) actuators, a class of soft artificial muscles, offer high performance but exhibit memory effects and hysteresis. Here we present a data-driven reduction and control strategy grounded in spectral submanifold (SSM) theory. In the adiabatic regime, where inputs vary slowly relative to intrinsic transients, trajectories rapidly converge to a low-dimensional slow manifold. We learn an explicit input-to-output map on this manifold from forced-response trajectories alone, avoiding decay experiments that can trigger hysteresis. We deploy the SSM-based model for real-time control of an antagonistic HASEL-clutch joint. This approach yields a substantial reduction in tracking error compared to feedback-only and feedforward-only baselines under identical settings. This record-and-control workflow enables rapid characterization and high-performance control of soft muscles and muscle-driven joints without detailed physics-based modeling.





## Indicating Robot Vision Capabilities with Augmented Reality
- **Url**: http://arxiv.org/abs/2511.03550v2
- **Authors**: ['Hong Wang', 'Ridhima Phatak', 'James Ocampo', 'Zhao Han']
- **Abstrat**: Research indicates that humans can mistakenly assume that robots and humans have the same field of view, possessing an inaccurate mental model of robots. This misperception may lead to failures during human-robot collaboration tasks where robots might be asked to complete impossible tasks about out-of-view objects. The issue is more severe when robots do not have a chance to scan the scene to update their world model while focusing on assigned tasks.   To help align humans' mental models of robots' vision capabilities, we propose four field-of-view indicators in augmented reality and conducted a human-subjects experiment (N=41) to evaluate them in a collaborative assembly task regarding accuracy, confidence, task efficiency, and workload. These indicators span a spectrum of positions: two at robot's eye and head space -- deepening eye socket and adding blocks to two sides of the eyes (i.e., egocentric), and two anchoring in the robot's task space -- adding extended blocks from the sides of eyes to the table and placing blocks directly on the tables (i.e., allocentric).   Results showed that, when placed directly in the task space, the allocentric indicator yields the highest accuracy, although with a delay in interpreting the robot's field of view. When placed at the robot's eyes, the egocentric indicator of deeper eye sockets, possible for physical alteration, also increased accuracy. In all indicators, participants' confidence was high while cognitive load remained low. Finally, we contribute six guidelines for practitioners to apply our augmented reality indicators or physical alterations to align humans' mental models with robots' vision capabilities.




